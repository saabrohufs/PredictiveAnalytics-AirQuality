{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive Analytics of Air Quality for IoT- Enabled Industrial Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38354a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code implemnents Hybrid LSTM Models and Several Classifiers for Air quality prediction \n",
    "# and classification tasks repectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c19259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Learning LSTM (HL-LSTM) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325aaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/airparticle.csv')\n",
    "\n",
    "# Convert timestamp to datetime and sort by time\n",
    "df['ts_received'] = pd.to_datetime(df['ts_received'])\n",
    "df = df.sort_values('ts_received')\n",
    "\n",
    "# Extract useful time-based features from the timestamp\n",
    "df['hour'] = df['ts_received'].dt.hour\n",
    "df['day'] = df['ts_received'].dt.day\n",
    "df['month'] = df['ts_received'].dt.month\n",
    "df['day_of_week'] = df['ts_received'].dt.dayofweek\n",
    "\n",
    "# Include the new features in the feature set\n",
    "features = df[['voc', 'mc_1p0', 'mc_2p5', 'mc_10p0', 'mc_4p0', 'ambient_rh', 'ambient_t', 'nox_index', 'voc_index',\n",
    "               'hour', 'day', 'month', 'day_of_week']].values\n",
    "\n",
    "# Extract features and targets\n",
    "#features = df[['voc', 'mc_1p0', 'mc_2p5', 'mc_10p0', 'mc_4p0', 'ambient_rh', 'ambient_t', 'nox_index', 'voc_index']].values\n",
    "y_pred = df['co2'].values  # AQI Prediction target using 'co2'\n",
    "y_class = df['class'].values  # Classification target\n",
    "\n",
    "# Note: Each air quality pollutant target is tested seperately\n",
    "# please switch between your target variable for the required prediction\n",
    "\n",
    "#target = 'voc'\n",
    "#target = 'mc_2p5'\n",
    "#target = 'mc_10p0'\n",
    "#target = 'nox_index'\n",
    "\n",
    "\n",
    "# Check for NaN or Infinite values\n",
    "features = np.nan_to_num(features)\n",
    "y_pred = np.nan_to_num(y_pred)\n",
    "\n",
    "# Normalize the feature columns\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(features)\n",
    "\n",
    "# Normalize the target (AQI Prediction, using 'co2')\n",
    "scaler_y = MinMaxScaler()\n",
    "y_pred_scaled = scaler_y.fit_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(features, target, n_timesteps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(features) - n_timesteps):\n",
    "        Xs.append(features[i:i + n_timesteps])\n",
    "        ys.append(target[i + n_timesteps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "n_timesteps = 10\n",
    "\n",
    "# Create sequences for both features and targets after normalization\n",
    "X, y_pred_seq = create_sequences(X_scaled, y_pred_scaled, n_timesteps)\n",
    "_, y_class_seq = create_sequences(X_scaled, y_class, n_timesteps)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train_pred, y_test_pred, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_pred_seq, y_class_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check data shapes\n",
    "print(X_train.shape, y_train_pred.shape, y_train_class.shape)\n",
    "\n",
    "# Check the unique class labels\n",
    "print(np.unique(y_class))\n",
    "\n",
    "# Model definition\n",
    "input_layer = Input(shape=(n_timesteps, X_train.shape[2]))\n",
    "\n",
    "# Shared LSTM Encoder\n",
    "shared_lstm = LSTM(128, activation='relu')(input_layer)\n",
    "shared_lstm = Dropout(0.4)(shared_lstm)\n",
    "\n",
    "# Prediction Head (AQI prediction)\n",
    "prediction_head = Dense(64, activation='relu')(shared_lstm)\n",
    "prediction_output = Dense(1, activation='linear', name='AQI_Prediction')(prediction_head)\n",
    "\n",
    "# Adjust the Classification Head for 6 classes (if there are 6 unique classes)\n",
    "classification_head = Dense(64, activation='relu')(shared_lstm)\n",
    "classification_output = Dense(6, activation='softmax', name='AQI_Classification')(classification_head)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=[prediction_output, classification_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss={'AQI_Prediction': 'Huber', 'AQI_Classification': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'AQI_Prediction': 'mse', 'AQI_Classification': 'accuracy'})\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, {'AQI_Prediction': y_train_pred, 'AQI_Classification': y_train_class},\n",
    "                    validation_split=0.2,\n",
    "                    epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, {'AQI_Prediction': y_test_pred, 'AQI_Classification': y_test_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55969317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following section provides implementation of different classification models that are used for \n",
    "# - air particle quality classfication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Extract features from LSTM encoder\n",
    "feature_extractor = Model(inputs=input_layer, outputs=shared_lstm)\n",
    "train_features = feature_extractor.predict(X_train)\n",
    "test_features = feature_extractor.predict(X_test)\n",
    "\n",
    "# Train RandomForest Classifier\n",
    "start_time = time.time()\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "rf_clf.fit(train_features, y_train_class)\n",
    "rf_preds = rf_clf.predict(test_features)\n",
    "rf_accuracy = accuracy_score(y_test_class, rf_preds)\n",
    "print(f\"RandomForest Accuracy: {rf_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa138b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(n_estimators=20, random_state=42)\n",
    "lgb_clf.fit(train_features, y_train_class)\n",
    "lgb_preds = lgb_clf.predict(test_features)\n",
    "lgb_accuracy = accuracy_score(y_test_class, lgb_preds)\n",
    "print(f\"LightGBM Accuracy: {lgb_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Train KNN Classifier\n",
    "start_time = time.time()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors\n",
    "knn_clf.fit(train_features, y_train_class)\n",
    "knn_preds = knn_clf.predict(test_features)\n",
    "knn_accuracy = accuracy_score(y_test_class, knn_preds)\n",
    "print(f\"KNN Accuracy: {knn_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be307f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "start_time = time.time()\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=20, max_depth=6, random_state=42, use_label_encoder=False)\n",
    "xgb_clf.fit(train_features, y_train_class)\n",
    "xgb_preds = xgb_clf.predict(test_features)\n",
    "xgb_accuracy = accuracy_score(y_test_class, xgb_preds)\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GradientBoosting Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "# Extract features from LSTM encoder\n",
    "feature_extractor = Model(inputs=input_layer, outputs=shared_lstm)\n",
    "train_features = feature_extractor.predict(X_train)\n",
    "test_features = feature_extractor.predict(X_test)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gb_clf.fit(train_features, y_train_class)\n",
    "gb_preds = gb_clf.predict(test_features)\n",
    "gb_accuracy = accuracy_score(y_test_class, gb_preds)\n",
    "print(f\"GradientBoosting Accuracy: {gb_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160408eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVC Classifier\n",
    "start_time = time.time()\n",
    "svc_clf = SVC(probability=True, random_state=42)\n",
    "svc_clf.fit(train_features, y_train_class)\n",
    "svc_preds = svc_clf.predict(test_features)\n",
    "svc_accuracy = accuracy_score(y_test_class, svc_preds)\n",
    "print(f\"SVC Accuracy: {svc_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb835a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ae026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "# Extract features from LSTM encoder\n",
    "feature_extractor = Model(inputs=input_layer, outputs=shared_lstm)\n",
    "train_features = feature_extractor.predict(X_train)\n",
    "test_features = feature_extractor.predict(X_test)\n",
    "# Train MLP Classifier\n",
    "start_time = time.time()\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, random_state=42)  # Adjust hidden layers and iterations\n",
    "mlp_clf.fit(train_features, y_train_class)\n",
    "mlp_preds = mlp_clf.predict(test_features)\n",
    "mlp_accuracy = accuracy_score(y_test_class, mlp_preds)\n",
    "print(f\"MLP Accuracy: {mlp_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Train Logistic Regression Classifier\n",
    "start_time = time.time()\n",
    "lr_clf = LogisticRegression(random_state=42, max_iter=50)  # Increase max_iter if needed\n",
    "lr_clf.fit(train_features, y_train_class)\n",
    "lr_preds = lr_clf.predict(test_features)\n",
    "lr_accuracy = accuracy_score(y_test_class, lr_preds)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "start_time = time.time()\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(train_features, y_train_class)\n",
    "nb_preds = nb_clf.predict(test_features)\n",
    "nb_accuracy = accuracy_score(y_test_class, nb_preds)\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy}, Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
